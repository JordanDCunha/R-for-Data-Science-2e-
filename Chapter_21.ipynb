{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQk9jkoZdxsIQb0usBFKsx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JordanDCunha/R-for-Data-Science-2e-/blob/main/Chapter_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 21.1 Introduction\n",
        "A huge amount of data lives in **databases**, so knowing how to access them directly is essential. Relying on someone else to export `.csv` snapshots quickly becomes inefficient—every change requires another manual step. Instead, you want to query databases **on demand**, pulling exactly the data you need, when you need it.\n",
        "\n",
        "In this chapter, you’ll learn the basics of working with databases from R using the **DBI** package. DBI provides the low-level tools to connect to databases and execute queries written in **SQL** (Structured Query Language), the standard language used to interact with databases.\n",
        "\n",
        "Rather than starting with raw SQL, the chapter introduces **dbplyr**, which translates familiar `dplyr` code into SQL behind the scenes. This lets you:\n",
        "- Work with databases using tidyverse-style syntax\n",
        "- Learn key SQL concepts gradually\n",
        "- Understand how common data manipulation verbs map to SQL operations\n",
        "\n",
        "By the end of the chapter, you won’t be a SQL expert—but you’ll recognize the most important SQL components and understand how they fit together.\n",
        "\n",
        "## 21.1.1 Prerequisites\n",
        "This chapter uses:\n",
        "- **DBI** for database connections and query execution\n",
        "- **dbplyr** to translate `dplyr` code into SQL\n",
        "- **tidyverse** for data manipulation workflows\n"
      ],
      "metadata": {
        "id": "3xWf6Tg2uMbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(DBI)\n",
        "library(dbplyr)\n",
        "library(tidyverse)\n"
      ],
      "metadata": {
        "id": "Np-01ClJuM6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 21.2 Database basics\n",
        "At a high level, a **database** can be thought of as a collection of data frames, called **tables**. Like data frames, tables consist of named columns where each column contains values of a single type. However, there are some important differences:\n",
        "\n",
        "### Data frames vs database tables\n",
        "- **Storage**: Database tables live on disk and can be arbitrarily large, while data frames live in memory and are limited by available RAM.\n",
        "- **Indexes**: Database tables usually have **indexes**, which allow fast lookup of specific rows (similar to a book index). Data frames don’t have indexes (though `data.table` does, which helps explain its speed).\n",
        "- **Optimization**: Traditional databases are optimized for **data collection**, not analysis. They are typically **row-oriented** (stored row by row), whereas R works column-by-column. Newer **column-oriented** databases greatly improve analytical performance.\n",
        "\n",
        "### Types of database management systems (DBMSs)\n",
        "Databases are managed by DBMSs, which generally fall into three categories:\n",
        "\n",
        "- **Client–server DBMSs**  \n",
        "  Run on a central server and are accessed by multiple clients. Ideal for shared, organizational data.  \n",
        "  Examples: PostgreSQL, MariaDB, SQL Server, Oracle.\n",
        "\n",
        "- **Cloud DBMSs**  \n",
        "  Similar to client–server systems but hosted in the cloud, allowing elastic scaling and massive datasets.  \n",
        "  Examples: Snowflake, Amazon Redshift, Google BigQuery.\n",
        "\n",
        "- **In-process DBMSs**  \n",
        "  Run entirely on your local machine. Best when you’re the primary user working with large datasets.  \n",
        "  Examples: SQLite, duckdb.\n"
      ],
      "metadata": {
        "id": "kM1xWa4QuPHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 21.3 Connecting to a database\n",
        "\n",
        "To connect to a database from R, you typically use **two kinds of packages**:\n",
        "\n",
        "### DBI (Database Interface)\n",
        "- **DBI** provides a common set of functions for connecting to databases, sending queries, and retrieving results.\n",
        "- You will *always* use DBI, regardless of the database.\n",
        "\n",
        "### A DBMS-specific package\n",
        "- Each database management system (DBMS) has its own package that translates DBI’s generic commands into database-specific instructions.\n",
        "- Examples:\n",
        "  - PostgreSQL → `RPostgres`\n",
        "  - MySQL / MariaDB → `RMariaDB`\n",
        "- If no dedicated package exists, you can usually fall back on **`odbc`**, which works with many databases but requires extra setup (drivers + configuration).\n",
        "\n",
        "### Creating a connection\n",
        "Connections are created with `DBI::dbConnect()`.  \n",
        "- The **first argument** specifies the DBMS.\n",
        "- The remaining arguments describe how to connect (host, port, credentials, etc.).\n",
        "- Connection details vary by database, so some trial and error (and help from a DBA or teammates) is normal.\n",
        "\n",
        "---\n",
        "\n",
        "## 21.3.1 In this book: duckdb\n",
        "Instead of setting up a server or cloud database, this book uses **duckdb**, an **in-process DBMS** that runs entirely inside R.\n",
        "\n",
        "Why duckdb?\n",
        "- Extremely easy to set up\n",
        "- Very fast and designed for data analysis\n",
        "- Uses DBI, so everything you learn transfers to other databases\n",
        "\n",
        "By default, duckdb creates a **temporary database** that disappears when R closes.  \n",
        "For real projects, you can create a **persistent database** by supplying a directory.\n",
        "\n",
        "---\n",
        "\n",
        "## 21.3.2 Loading data\n",
        "Once connected, you need to load data into the database.  \n",
        "`DBI::dbWriteTable()` creates a table from a data frame.\n",
        "\n",
        "For real-world duckdb usage, faster alternatives include:\n",
        "- `duckdb_read_csv()`\n",
        "- `duckdb_register_arrow()`\n",
        "\n",
        "(these avoid loading data fully into R first).\n",
        "\n",
        "---\n",
        "\n",
        "## 21.3.3 DBI basics\n",
        "Useful DBI functions include:\n",
        "- `dbListTables()` — list tables in the database\n",
        "- `dbReadTable()` — read an entire table into R\n",
        "- `dbGetQuery()` — run raw SQL and return the result\n",
        "\n",
        "If SQL is new to you, don’t stress: you’ll learn it gradually. For now, it’s enough to recognize that SQL queries specify **columns to select** and **rows to keep**.\n"
      ],
      "metadata": {
        "id": "nC2PA6vzvUVS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlguZn8mle2Y"
      },
      "outputs": [],
      "source": [
        "# Load required packages\n",
        "library(DBI)\n",
        "library(duckdb)\n",
        "library(tidyverse)\n",
        "\n",
        "# Connect to a temporary duckdb database\n",
        "con <- DBI::dbConnect(duckdb::duckdb())\n",
        "\n",
        "# Load example datasets into the database\n",
        "dbWriteTable(con, \"mpg\", ggplot2::mpg)\n",
        "dbWriteTable(con, \"diamonds\", ggplot2::diamonds)\n",
        "\n",
        "# List tables in the database\n",
        "dbListTables(con)\n",
        "\n",
        "# Read a table back into R\n",
        "con |>\n",
        "  dbReadTable(\"diamonds\") |>\n",
        "  as_tibble()\n",
        "\n",
        "# Run a raw SQL query\n",
        "sql <- \"\n",
        "  SELECT carat, cut, clarity, color, price\n",
        "  FROM diamonds\n",
        "  WHERE price > 15000\n",
        "\"\n",
        "\n",
        "as_tibble(dbGetQuery(con, sql))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 21.4 dbplyr basics\n",
        "\n",
        "Now that we’ve connected to a database and loaded data, we can introduce **dbplyr**.  \n",
        "dbplyr is a *dplyr backend*, meaning you keep writing familiar **dplyr** code, but instead of running directly in R, your code is **translated into SQL** and executed inside the database.\n",
        "\n",
        "Other dplyr backends include:\n",
        "- **dtplyr** → translates to `data.table`\n",
        "- **multidplyr** → runs code across multiple cores\n",
        "\n",
        "---\n",
        "\n",
        "## Working with database tables\n",
        "To use dbplyr, you first create a reference to a database table using `tbl()`:\n",
        "\n",
        "- This does **not** load the data into R.\n",
        "- It creates a *lazy* object that represents a table or query in the database.\n",
        "\n",
        "In larger systems, tables may live inside **schemas** or **catalogs**, which help organize many tables.  \n",
        "You can also start from a **custom SQL query** if needed.\n",
        "\n",
        "---\n",
        "\n",
        "## Lazy evaluation\n",
        "dbplyr objects are *lazy*.  \n",
        "When you apply dplyr verbs like `filter()` or `select()`, **no computation happens immediately**. Instead, dbplyr records the operations and only runs them when results are actually needed.\n",
        "\n",
        "This is why:\n",
        "- You often don’t see the number of rows\n",
        "- Printing is fast, even for huge datasets\n",
        "\n",
        "---\n",
        "\n",
        "## Translating dplyr to SQL\n",
        "You can inspect the SQL generated by your dplyr code using `show_query()`.  \n",
        "This is a powerful way to *learn SQL by example*: write dplyr, then see how it maps to SQL.\n",
        "\n",
        "---\n",
        "\n",
        "## Bringing data back into R\n",
        "To actually retrieve results from the database, use `collect()`:\n",
        "- dbplyr generates the SQL\n",
        "- DBI runs the query\n",
        "- Results are returned as a tibble in R\n",
        "\n",
        "**Typical workflow**:\n",
        "1. Filter, select, and aggregate data in the database (fast, scalable)\n",
        "2. `collect()` once the dataset is small enough\n",
        "3. Continue analysis with R-specific tools\n"
      ],
      "metadata": {
        "id": "kwC7gDpOv-OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load required packages\n",
        "library(DBI)\n",
        "library(dbplyr)\n",
        "library(duckdb)\n",
        "library(tidyverse)\n",
        "\n",
        "# Connect to duckdb\n",
        "con <- DBI::dbConnect(duckdb::duckdb())\n",
        "\n",
        "# Reference a database table (lazy)\n",
        "diamonds_db <- tbl(con, \"diamonds\")\n",
        "\n",
        "# Build a lazy query using dplyr\n",
        "big_diamonds_db <- diamonds_db |>\n",
        "  filter(price > 15000) |>\n",
        "  select(carat:clarity, price)\n",
        "\n",
        "# View the generated SQL\n",
        "big_diamonds_db |>\n",
        "  show_query()\n",
        "\n",
        "# Collect results into R\n",
        "big_diamonds <- big_diamonds_db |>\n",
        "  collect()\n",
        "\n",
        "big_diamonds\n"
      ],
      "metadata": {
        "id": "nJT2YdLXv_d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 21.5 SQL\n",
        "\n",
        "This section introduces **SQL through dbplyr**, using your existing dplyr knowledge as a bridge. Rather than learning SQL syntax in isolation, you see how familiar dplyr verbs are **translated into SQL queries** behind the scenes.\n",
        "\n",
        "We work with the **nycflights13** datasets (`flights`, `planes`) copied into a database, then explore how dplyr pipelines map onto SQL.\n",
        "\n",
        "---\n",
        "\n",
        "## SQL structure\n",
        "SQL queries are built from **clauses**. The most important ones are:\n",
        "\n",
        "- **SELECT** – choose, create, or rename columns  \n",
        "- **FROM** – specify the data source  \n",
        "- **WHERE** – filter rows  \n",
        "- **GROUP BY** – define groups for aggregation  \n",
        "- **ORDER BY** – sort rows  \n",
        "\n",
        "Every query must include `SELECT` and `FROM`.  \n",
        "Although SQL is written in the order `SELECT → FROM → WHERE → GROUP BY → ORDER BY`, it is *evaluated* in a different order internally.\n",
        "\n",
        "---\n",
        "\n",
        "## dplyr ↔ SQL mappings\n",
        "\n",
        "### SELECT\n",
        "- `select()`, `rename()`, `relocate()` → column selection and aliasing\n",
        "- `mutate()` → computed expressions inside `SELECT`\n",
        "- Renaming uses **AS** in SQL\n",
        "- Reserved words (e.g., `year`, `type`) are quoted automatically\n",
        "\n",
        "### FROM\n",
        "- Defines the table or subquery used as input\n",
        "- Becomes more interesting once joins are introduced\n",
        "\n",
        "### WHERE\n",
        "- `filter()` → `WHERE`\n",
        "- `|` → `OR`, `&` → `AND`\n",
        "- `==` → `=`\n",
        "- `%in%` → `IN`\n",
        "- SQL uses **NULL** instead of `NA`\n",
        "- Filters on summarized values generate **HAVING**, not `WHERE`\n",
        "\n",
        "### GROUP BY\n",
        "- `group_by()` → `GROUP BY`\n",
        "- `summarize()` → aggregation expressions in `SELECT`\n",
        "- SQL drops NULLs automatically in summaries (dbplyr warns you)\n",
        "\n",
        "### ORDER BY\n",
        "- `arrange()` → `ORDER BY`\n",
        "- `desc()` → `DESC`\n",
        "\n",
        "---\n",
        "\n",
        "## Subqueries\n",
        "Sometimes dbplyr must generate **subqueries** to match SQL’s evaluation rules.  \n",
        "This happens when:\n",
        "- You reference a variable created earlier in the same pipeline\n",
        "- You filter on a newly created column\n",
        "\n",
        "Subqueries appear as nested `SELECT` statements in the `FROM` clause.\n",
        "\n",
        "---\n",
        "\n",
        "## Joins\n",
        "dplyr joins map almost directly to SQL joins:\n",
        "\n",
        "- `left_join()` → `LEFT JOIN`\n",
        "- `inner_join()` → `INNER JOIN`\n",
        "- `right_join()` → `RIGHT JOIN`\n",
        "- `full_join()` → `FULL JOIN`\n",
        "\n",
        "SQL joins live inside the `FROM` clause and use **ON** to define key relationships.\n",
        "\n",
        "---\n",
        "\n",
        "## Beyond the basics\n",
        "dbplyr also translates:\n",
        "- `distinct()`\n",
        "- `slice_*()`\n",
        "- set operations like `intersect()`\n",
        "- selected tidyr verbs (e.g., `pivot_longer()`, `pivot_wider()`)\n",
        "\n",
        "Because SQL dialects vary across databases, dbplyr adapts its translations automatically—imperfectly, but increasingly well.\n",
        "\n",
        "---\n",
        "\n",
        "## Key idea\n",
        "Use **databases for filtering, grouping, and joining**, then `collect()` once the data is small enough for in-memory R analysis. This gives you scalability without giving up dplyr.\n"
      ],
      "metadata": {
        "id": "Dbarz8bnwfiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load packages\n",
        "library(DBI)\n",
        "library(dbplyr)\n",
        "library(tidyverse)\n",
        "library(nycflights13)\n",
        "\n",
        "# Copy nycflights13 tables into the database\n",
        "dbplyr::copy_nycflights13(con)\n",
        "\n",
        "# Reference tables lazily\n",
        "flights <- tbl(con, \"flights\")\n",
        "planes  <- tbl(con, \"planes\")\n",
        "\n",
        "# Example: filtering and ordering\n",
        "flights |>\n",
        "  filter(dest %in% c(\"IAH\", \"HOU\")) |>\n",
        "  arrange(desc(dep_delay)) |>\n",
        "  show_query()\n",
        "\n",
        "# Example: grouping and summarizing\n",
        "flights |>\n",
        "  group_by(dest) |>\n",
        "  summarize(avg_delay = mean(arr_delay, na.rm = TRUE)) |>\n",
        "  show_query()\n",
        "\n",
        "# Example: join\n",
        "flights |>\n",
        "  left_join(planes |> rename(year_built = year), join_by(tailnum)) |>\n",
        "  show_query()\n"
      ],
      "metadata": {
        "id": "WKozz84lwhac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 21.6 Function translations\n",
        "\n",
        "This section zooms in on how **individual R functions** (used inside `summarize()` and `mutate()`) are translated by **dbplyr** into SQL expressions.\n",
        "\n",
        "## Aggregation vs window functions\n",
        "- In `summarize()`, functions like `mean()` or `median()` become **SQL aggregation functions** (e.g., `AVG()`, `MEDIAN()`).\n",
        "- In `mutate()`, the same functions become **window functions**, using `OVER (...)`, because results must be computed per row rather than collapsing rows.\n",
        "\n",
        "## Window functions\n",
        "- Grouping variables move from `GROUP BY` into `PARTITION BY` inside `OVER`.\n",
        "- Ordering must be explicit with `arrange()` because SQL tables have no inherent row order.\n",
        "- Functions like `lead()` and `lag()` are classic window functions and require both partitioning and ordering.\n",
        "\n",
        "## Conditional logic\n",
        "- `if_else()` and `case_when()` translate to SQL’s **CASE WHEN** syntax.\n",
        "- Functions without direct SQL equivalents (e.g., `cut()`) are also implemented using `CASE WHEN`.\n",
        "\n",
        "## Key takeaway\n",
        "dbplyr translates many common R functions into SQL—sometimes simply, sometimes with complex expressions. When translations are unavailable, computation must happen after `collect()`. For most day-to-day analysis, dbplyr covers the functions you’ll use most often.\n"
      ],
      "metadata": {
        "id": "rH2z96Rmw03x"
      }
    }
  ]
}